name: Generate DataQuality Baseline (one-off)

on:
  workflow_dispatch:
    inputs:
      dataset_s3:
        description: "학습 데이터 S3 URI (CSV/JSONL)"
        required: true
      baseline_prefix:
        description: "Baseline 저장 S3 prefix (끝에 /)"
        required: true
      instance_type:
        description: "Processing 인스턴스 타입"
        required: false
        default: "ml.m5.xlarge"

  workflow_call:                      
    inputs:
      dataset_s3:
        required: true
        type: string
      baseline_prefix:
        required: true
        type: string
      instance_type:
        required: false
        type: string
        default: "ml.m5.xlarge"

permissions:
  id-token: write
  contents: read

jobs:
  gen-baseline:
    runs-on: ubuntu-latest
    steps:
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Generate baseline with SageMaker Processing
        run: |
          IMAGE="${{ vars.MONITOR_IMAGE_URI }}"  # Model Monitor Analyzer 이미지 URI
          ROLE="${{ secrets.SAGEMAKER_PROCESSING_ROLE_ARN || vars.SAGEMAKER_PROCESSING_ROLE_ARN }}"
          DATASET="${{ github.event.inputs.dataset_s3 }}"
          BASELINE="${{ github.event.inputs.baseline_prefix }}"
          ITYPE="${{ github.event.inputs.instance_type }}"

          JOB_NAME="dq-baseline-$(date +%Y%m%d-%H%M%S)"

          aws sagemaker create-processing-job \
            --processing-job-name "$JOB_NAME" \
            --app-specification "ImageUri=$IMAGE,ContainerArguments=[baseline]" \
            --role-arn "$ROLE" \
            --processing-resources "ClusterConfig={InstanceCount=1,InstanceType=$ITYPE,VolumeSizeInGB=30}" \
            --processing-inputs "[{InputName=dataset,S3Input={S3Uri=$DATASET,LocalPath=/opt/ml/processing/input,S3DataType=S3Prefix,S3InputMode=File}}]" \
            --processing-output-config "Outputs=[{OutputName=baseline,S3Output={S3Uri=${BASELINE}dataquality/,LocalPath=/opt/ml/processing/output,S3UploadMode=EndOfJob}}]" \
            --stopping-condition "MaxRuntimeInSeconds=3600"

          echo "Started ProcessingJob: $JOB_NAME"

